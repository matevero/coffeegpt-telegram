from flask import Flask, request
import openai
import os
import telegram
from dotenv import load_dotenv
import traceback

# Carrega vari√°veis do .env
load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
bot = telegram.Bot(token=TELEGRAM_TOKEN)
openai.api_key = OPENAI_API_KEY

app = Flask(__name__)

@app.route(f"/{TELEGRAM_TOKEN}", methods=["POST"])
def respond():
    update = telegram.Update.de_json(request.get_json(force=True), bot)
    chat_id = update.message.chat.id
    user_message = update.message.text

    try:
        # Chamada √† API de chat da OpenAI
        response = openai.chat_completions.create(
            model="gpt-3.5-turbo",  # Modelo do chat
            messages=[
                {"role": "system", "content": "Voc√™ √© o CoffeeGPT, um assistente simp√°tico para produtores de caf√©."},
                {"role": "user", "content": user_message}
            ]
        )
        
        # Verificar o conte√∫do da resposta antes de enviar
        print("Resposta recebida:", response)

        # Obter a resposta do modelo
        response_text = response['choices'][0]['message']['content']
        bot.send_message(chat_id=chat_id, text=response_text)

    except Exception as e:
        # Log detalhado do erro
        error_message = f"Erro: {str(e)}\n{traceback.format_exc()}"
        bot.send_message(chat_id=chat_id, text="Eita, deu ruim aqui na mente do CoffeeGPT üòÖ")
        print(error_message)

    return "ok"

@app.route("/webhook", methods=["GET"])
def webhook_status():
    return "Webhook est√° funcionando!"

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)



